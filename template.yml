AWSTemplateFormatVersion: '2010-09-09'
Description: "Kafka Cluster - Three EC2 brokers running Apache Kafka 4.x in KRaft mode"

Parameters:
  KeyName:
    Type: AWS::EC2::KeyPair::KeyName
    Description: Name of an existing EC2 KeyPair to enable SSH access

Resources:
  MyVPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsHostnames: true
      Tags:
        - Key: Name
          Value: MyVPC

  MyInternetGateway:
    Type: AWS::EC2::InternetGateway

  AttachGateway:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId: !Ref MyVPC
      InternetGatewayId: !Ref MyInternetGateway

  MyPublicSubnet:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref MyVPC
      CidrBlock: 10.0.0.0/24
      MapPublicIpOnLaunch: true

  MyRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref MyVPC

  PublicRoute:
    Type: AWS::EC2::Route
    Properties:
      RouteTableId: !Ref MyRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref MyInternetGateway

  SubnetAssoc:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref MyPublicSubnet
      RouteTableId: !Ref MyRouteTable

  KafkaSG:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Allow Kafka traffic & SSH
      VpcId: !Ref MyVPC
      SecurityGroupIngress:
        # SSH
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0

        # HTTP Log Server
        - IpProtocol: tcp
          FromPort: 8000
          ToPort: 8000
          CidrIp: 0.0.0.0/0

        # Kafka brokers
        - IpProtocol: tcp
          FromPort: 9092
          ToPort: 9094
          CidrIp: 10.0.0.0/16

        # KRaft quorum ports
        - IpProtocol: tcp
          FromPort: 29092
          ToPort: 29094
          CidrIp: 10.0.0.0/16

      Tags:
        - Key: Name
          Value: KafkaSG

  AppInstanceSG:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Allow SSH and outbound to Kafka
      VpcId: !Ref MyVPC
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 8080
          ToPort: 8080
          CidrIp: 0.0.0.0/0
      SecurityGroupEgress:
        - IpProtocol: -1
          CidrIp: 0.0.0.0/0
      Tags:
        - Key: Name
          Value: AppInstanceSG

  ############################
  #   BROKER USER-DATA BASE  #
  ############################

  KafkaUserData1:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
        ImageId: ami-0d176f79571d18a8f
        InstanceType: t3.small
        KeyName: !Ref KeyName
        SecurityGroupIds: [!Ref KafkaSG]
        UserData:
          Fn::Base64: |
            #!/bin/bash
            set -eux

            yum update -y
            yum install -y java-17-amazon-corretto wget tar nmap-ncat python3

            # Start HTTP server for logs before Kafka setup
            mkdir -p /var/log
            cd /var/log
            nohup python3 -m http.server 8000 > /var/log/http-server.log 2>&1 &
            echo "HTTP log server started on port 8000"

            cd /opt
            wget https://downloads.apache.org/kafka/4.1.1/kafka_2.13-4.1.1.tgz
            tar -xzf kafka_2.13-4.1.1.tgz
            mv kafka_2.13-4.1.1 kafka

            KAFKA_HOME=/opt/kafka

            CLUSTER_ID=$($KAFKA_HOME/bin/kafka-storage.sh random-uuid)

            mkdir -p $KAFKA_HOME/config/kraft

            cat > $KAFKA_HOME/config/kraft/server.properties <<EOF
            process.roles=broker,controller
            node.id=1
            controller.quorum.voters=1@10.0.0.10:29092,2@10.0.0.11:29093,3@10.0.0.12:29094
            listeners=PLAINTEXT://10.0.0.10:9092,CONTROLLER://10.0.0.10:29092
            log.dirs=/tmp/kraft-combined-logs
            EOF

            $KAFKA_HOME/bin/kafka-storage.sh format -t $CLUSTER_ID -c $KAFKA_HOME/config/kraft/server.properties

            nohup $KAFKA_HOME/bin/kafka-server-start.sh $KAFKA_HOME/config/kraft/server.properties >/var/log/kafka.log 2>&1 &


  KafkaUserData2:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
        ImageId: ami-0d176f79571d18a8f
        InstanceType: t3.small
        KeyName: !Ref KeyName
        SecurityGroupIds: [!Ref KafkaSG]
        UserData:
          Fn::Base64: |
            #!/bin/bash
            set -eux

            yum update -y
            yum install -y java-17-amazon-corretto wget tar nmap-ncat python3

            # Start HTTP server for logs before Kafka setup
            mkdir -p /var/log
            cd /var/log
            nohup python3 -m http.server 8000 > /var/log/http-server.log 2>&1 &
            echo "HTTP log server started on port 8000"

            cd /opt
            wget https://downloads.apache.org/kafka/4.1.1/kafka_2.13-4.1.1.tgz
            tar -xzf kafka_2.13-4.1.1.tgz
            mv kafka_2.13-4.1.1 kafka

            KAFKA_HOME=/opt/kafka
            CLUSTER_ID=$($KAFKA_HOME/bin/kafka-storage.sh random-uuid)

            mkdir -p $KAFKA_HOME/config/kraft

            cat > $KAFKA_HOME/config/kraft/server.properties <<EOF
            process.roles=broker,controller
            node.id=2
            controller.quorum.voters=1@10.0.0.10:29092,2@10.0.0.11:29093,3@10.0.0.12:29094
            listeners=PLAINTEXT://10.0.0.11:9093,CONTROLLER://10.0.0.11:29093
            log.dirs=/tmp/kraft-combined-logs
            EOF

            $KAFKA_HOME/bin/kafka-storage.sh format -t $CLUSTER_ID -c $KAFKA_HOME/config/kraft/server.properties

            nohup $KAFKA_HOME/bin/kafka-server-start.sh $KAFKA_HOME/config/kraft/server.properties >/var/log/kafka.log 2>&1 &


  KafkaUserData3:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
        ImageId: ami-0d176f79571d18a8f
        InstanceType: t3.small
        KeyName: !Ref KeyName
        SecurityGroupIds: [!Ref KafkaSG]
        UserData:
          Fn::Base64: |
            #!/bin/bash
            set -eux

            yum update -y
            yum install -y java-17-amazon-corretto wget tar nmap-ncat python3

            # Start HTTP server for logs before Kafka setup
            mkdir -p /var/log
            cd /var/log
            nohup python3 -m http.server 8000 > /var/log/http-server.log 2>&1 &
            echo "HTTP log server started on port 8000"

            cd /opt
            wget https://downloads.apache.org/kafka/4.1.1/kafka_2.13-4.1.1.tgz
            tar -xzf kafka_2.13-4.1.1.tgz
            mv kafka_2.13-4.1.1 kafka

            KAFKA_HOME=/opt/kafka
            CLUSTER_ID=$($KAFKA_HOME/bin/kafka-storage.sh random-uuid)

            mkdir -p $KAFKA_HOME/config/kraft

            cat > $KAFKA_HOME/config/kraft/server.properties <<EOF
            process.roles=broker,controller
            node.id=3
            controller.quorum.voters=1@10.0.0.10:29092,2@10.0.0.11:29093,3@10.0.0.12:29094
            listeners=PLAINTEXT://10.0.0.12:9094,CONTROLLER://10.0.0.12:29094
            log.dirs=/tmp/kraft-combined-logs
            EOF

            $KAFKA_HOME/bin/kafka-storage.sh format -t $CLUSTER_ID -c $KAFKA_HOME/config/kraft/server.properties

            nohup $KAFKA_HOME/bin/kafka-server-start.sh $KAFKA_HOME/config/kraft/server.properties >/var/log/kafka.log 2>&1 &


  ##########################
  #   BROKER INSTANCES     #
  ##########################

  Broker1:
    Type: AWS::EC2::Instance
    Properties:
      LaunchTemplate:
        LaunchTemplateId: !Ref KafkaUserData1
        Version: !GetAtt KafkaUserData1.LatestVersionNumber
      SubnetId: !Ref MyPublicSubnet
      PrivateIpAddress: 10.0.0.10
      Tags:
        - Key: Name
          Value: kafka-broker-1

  Broker2:
    Type: AWS::EC2::Instance
    Properties:
      LaunchTemplate:
        LaunchTemplateId: !Ref KafkaUserData2
        Version: !GetAtt KafkaUserData2.LatestVersionNumber
      SubnetId: !Ref MyPublicSubnet
      PrivateIpAddress: 10.0.0.11
      Tags:
        - Key: Name
          Value: kafka-broker-2

  Broker3:
    Type: AWS::EC2::Instance
    Properties:
      LaunchTemplate:
        LaunchTemplateId: !Ref KafkaUserData3
        Version: !GetAtt KafkaUserData3.LatestVersionNumber
      SubnetId: !Ref MyPublicSubnet
      PrivateIpAddress: 10.0.0.12
      Tags:
        - Key: Name
          Value: kafka-broker-3

  ##########################
  #   PRODUCER INSTANCE    #
  ##########################

  ProducerInstance:
    Type: AWS::EC2::Instance
    DependsOn: Broker1
    Properties:
      InstanceType: t3.small
      KeyName: !Ref KeyName
      ImageId: ami-0d176f79571d18a8f
      SubnetId: !Ref MyPublicSubnet
      SecurityGroupIds:
        - !Ref AppInstanceSG
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash
          set -eux
          
          yum update -y
          yum install -y java-17-amazon-corretto git maven nmap-ncat

          HOME_DIR=/home/ec2-user
          if [ -d /home/ubuntu ]; then HOME_DIR=/home/ubuntu; fi

          cd $HOME_DIR
          git clone https://github.com/devashish234073/kafka-experiments
          cd kafka-experiments/producer
          
          sed -i "s|localhost:9092|10.0.0.10:9092,10.0.0.11:9093,10.0.0.12:9094|g" src/main/resources/application.properties

          # wait for all brokers to be reachable (ports may differ)
          until nc -z 10.0.0.10 9092 && nc -z 10.0.0.11 9093 && nc -z 10.0.0.12 9094; do sleep 5; done

          nohup mvn spring-boot:run > /var/log/producer.log 2>&1 &
          echo "Producer started"
      Tags:
        - Key: Name
          Value: kafka-producer

  ##########################
  #   CONSUMER INSTANCE    #
  ##########################

  ConsumerInstance:
    Type: AWS::EC2::Instance
    DependsOn: Broker1
    Properties:
      InstanceType: t3.small
      KeyName: !Ref KeyName
      ImageId: ami-0d176f79571d18a8f
      SubnetId: !Ref MyPublicSubnet
      SecurityGroupIds:
        - !Ref AppInstanceSG
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash
          set -eux
          
          yum update -y
          yum install -y java-17-amazon-corretto git maven nmap-ncat

          HOME_DIR=/home/ec2-user
          if [ -d /home/ubuntu ]; then HOME_DIR=/home/ubuntu; fi

          cd $HOME_DIR
          git clone https://github.com/devashish234073/kafka-experiments
          cd kafka-experiments/consumer
          
          sed -i "s|localhost:9092|10.0.0.10:9092,10.0.0.11:9093,10.0.0.12:9094|g" src/main/resources/application.properties

          # wait for all brokers to be reachable (ports may differ)
          until nc -z 10.0.0.10 9092 && nc -z 10.0.0.11 9093 && nc -z 10.0.0.12 9094; do sleep 5; done

          nohup mvn spring-boot:run > /var/log/consumer.log 2>&1 &
          echo "Consumer started"
      Tags:
        - Key: Name
          Value: kafka-consumer

Outputs:
  Broker1IP:
    Value: !GetAtt Broker1.PrivateIp
  Broker2IP:
    Value: !GetAtt Broker2.PrivateIp
  Broker3IP:
    Value: !GetAtt Broker3.PrivateIp
  ProducerInstanceIP:
    Value: !GetAtt ProducerInstance.PublicIp
    Description: Producer Instance Public IP
  ConsumerInstanceIP:
    Value: !GetAtt ConsumerInstance.PublicIp
    Description: Consumer Instance Public IP
  ProducerUIURL:
    Value: !Sub 'http://${ProducerInstance.PublicIp}:8080'
    Description: Producer UI URL - send messages here
  ConsumerUIURL:
    Value: !Sub 'http://${ConsumerInstance.PublicIp}:8080'
    Description: Consumer UI URL - view received messages here
  Broker1LogURL:
    Value: !Sub 'http://${Broker1.PublicIp}:8000'
    Description: Broker 1 Log Server - browse logs from /var/log
  Broker2LogURL:
    Value: !Sub 'http://${Broker2.PublicIp}:8000'
    Description: Broker 2 Log Server - browse logs from /var/log
  Broker3LogURL:
    Value: !Sub 'http://${Broker3.PublicIp}:8000'
    Description: Broker 3 Log Server - browse logs from /var/log
